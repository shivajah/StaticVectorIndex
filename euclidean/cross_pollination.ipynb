{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6602c22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "import time\n",
    "import numpy as np\n",
    "import faiss\n",
    "import h5py\n",
    "import requests\n",
    "from collections import defaultdict\n",
    "import bisect\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "93b37a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Data Utilities ---\n",
    "\n",
    "def download_fashion_mnist(cache_path, url):\n",
    "    if not os.path.exists(cache_path):\n",
    "        print(\"Downloading Fashion-MNIST (~300 MB)â€¦\")\n",
    "        headers = {\"User-Agent\": \"Mozilla/5.0\"}\n",
    "        response = requests.get(url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            with open(cache_path, \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "        else:\n",
    "            raise Exception(f\"Failed to download dataset: HTTP{response.status_code}\")\n",
    "\n",
    "def load_fashion_mnist(cache_path):\n",
    "    with h5py.File(cache_path, \"r\") as f:\n",
    "        xb = f[\"train\"][:].astype(np.float32)\n",
    "        xq = f[\"test\"][:].astype(np.float32)\n",
    "        gt = f[\"neighbors\"][:]\n",
    "    return xb, xq, gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e30d11d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Indexing Utilities ---\n",
    "\n",
    "def build_kmeans(xb, d, n_clusters, niter=20):\n",
    "    train_sample = xb[np.random.choice(len(xb), size=min(50000, len(xb)), replace=False)]\n",
    "    kmeans = faiss.Kmeans(d, n_clusters, niter=niter, verbose=True, spherical=False)\n",
    "    kmeans.train(train_sample)\n",
    "    return kmeans\n",
    "\n",
    "def assign_vectors_to_clusters(xb, kmeans, n_assign):\n",
    "    _, assignments = kmeans.index.search(xb, n_assign)\n",
    "    return assignments\n",
    "\n",
    "def cross_pollinate_metadata(xb, xb_inner_assignments, inner_centroids, inner_to_outer, N_CROSS):\n",
    "    vector_metadata = defaultdict(dict)\n",
    "    for idx, inner_ids in enumerate(xb_inner_assignments):\n",
    "        for inner_id in inner_ids[:N_CROSS]:\n",
    "            outer_id = inner_to_outer[inner_id][0]\n",
    "            centroid = inner_centroids[inner_id]\n",
    "            vec = xb[idx]\n",
    "            dist = np.linalg.norm(vec - centroid)\n",
    "            cos_sim = np.dot(vec, centroid) / (np.linalg.norm(vec) * np.linalg.norm(centroid) + 1e-8)\n",
    "            vector_metadata[outer_id].setdefault(inner_id, []).append((dist, cos_sim, idx))\n",
    "    # Sort each list by Euclidean distance to centroid\n",
    "    for outer_id in vector_metadata:\n",
    "        for inner_id in vector_metadata[outer_id]:\n",
    "            vector_metadata[outer_id][inner_id].sort()\n",
    "    return vector_metadata\n",
    "\n",
    "def build_outer_to_num_inner_clusters(vector_metadata):\n",
    "    \"\"\"\n",
    "    Build a dictionary mapping each outer cluster id to the number of inner clusters it contains.\n",
    "    Args:\n",
    "        vector_metadata: dict[outer_id][inner_id] -> list of vectors\n",
    "    Returns:\n",
    "        outer_to_num_inner_clusters: dict[outer_id] -> int (number of inner clusters)\n",
    "    \"\"\"\n",
    "    outer_to_num_inner_clusters = {}\n",
    "    for outer_id in vector_metadata:\n",
    "        outer_to_num_inner_clusters[outer_id] = len(vector_metadata[outer_id])\n",
    "\n",
    "    print(\"\\nNumber of inner clusters for each outer cluster:\")\n",
    "    for outer_id in sorted(outer_to_num_inner_clusters):\n",
    "        print(f\"Outer cluster {outer_id}: {outer_to_num_inner_clusters[outer_id]} inner clusters\")\n",
    "    \n",
    "    return outer_to_num_inner_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ee892376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Search Utilities ---\n",
    "def pad_to_k(arr, k, pad_value):\n",
    "    arr = list(arr)\n",
    "    if len(arr) < k:\n",
    "        arr += [pad_value] * (k - len(arr))\n",
    "    return arr[:k]\n",
    "\n",
    "def search_query_cross_pollination(\n",
    "    x, outer_ids, inner_kmeans, vector_metadata, xb, k, d,\n",
    "    N_PROBE=1, probe_strategy=\"nprobe\", tshirt_size=\"small\", n_outer_total=10\n",
    "):\n",
    "    \"\"\"\n",
    "    Probes clusters using either N_PROBE or T-SHIRT size strategy.\n",
    "    T-SHIRT size: Small/Medium/Large, each probes a percentage of outer and inner clusters.\n",
    "    \"\"\"\n",
    "    # T-SHIRT size settings\n",
    "    tshirt_settings = {\n",
    "        \"small\": 0.10,\n",
    "        \"medium\": 0.20,\n",
    "        \"large\": 0.30\n",
    "    }\n",
    "    best_heap = []\n",
    "    tau = float(\"inf\")\n",
    "    probed_inner_ids = set()\n",
    "    inner_probed = 0\n",
    "\n",
    "    if probe_strategy == \"tshirt\":\n",
    "        pct = tshirt_settings[tshirt_size]\n",
    "        n_outer_probe = max(1, int(np.ceil(n_outer_total * pct)))\n",
    "        outer_ids = outer_ids[:n_outer_probe]\n",
    "    else:\n",
    "        # nprobe strategy: probe as many outer clusters as needed to reach N_PROBE inner clusters\n",
    "        n_outer_probe = len(outer_ids)\n",
    "\n",
    "    outer_idx = 0\n",
    "    total_outer = len(outer_ids)\n",
    "\n",
    "    while (probe_strategy == \"nprobe\" and inner_probed < N_PROBE and outer_idx < total_outer) or \\\n",
    "          (probe_strategy == \"tshirt\" and outer_idx < total_outer):\n",
    "        outer_id = outer_ids[outer_idx]\n",
    "        outer_idx += 1\n",
    "        if outer_id not in vector_metadata:\n",
    "            continue\n",
    "        inner_ids = list(vector_metadata[outer_id].keys())\n",
    "        if not inner_ids:\n",
    "            continue\n",
    "        if probe_strategy == \"tshirt\":\n",
    "            n_inner_probe = max(1, int(np.ceil(len(inner_ids) * tshirt_settings[tshirt_size])))\n",
    "        else:\n",
    "            n_inner_probe = min(N_PROBE - inner_probed, len(inner_ids))\n",
    "        inner_ids_to_probe = [iid for iid in inner_ids if iid not in probed_inner_ids][:n_inner_probe]\n",
    "        if not inner_ids_to_probe:\n",
    "            continue\n",
    "        inner_centroids_subset = inner_kmeans.centroids[inner_ids_to_probe]\n",
    "        index_l2 = faiss.IndexFlatL2(d)\n",
    "        index_l2.add(inner_centroids_subset)\n",
    "        _, inner_ranks_local = index_l2.search(x.reshape(1, -1), len(inner_ids_to_probe))\n",
    "        selected_inner_ids = [inner_ids_to_probe[j] for j in inner_ranks_local[0] if j < len(inner_ids_to_probe)]\n",
    "        for inner_id in selected_inner_ids:\n",
    "            probed_inner_ids.add(inner_id)\n",
    "            idxs_meta = vector_metadata[outer_id][inner_id]\n",
    "            if not idxs_meta:\n",
    "                continue\n",
    "            centroid = inner_kmeans.centroids[inner_id]\n",
    "            d_qc = np.linalg.norm(x - centroid)\n",
    "            for dist_ic, cos_theta, idx2 in idxs_meta:\n",
    "                lower_bound = abs(d_qc - dist_ic)\n",
    "                if lower_bound > tau:\n",
    "                    continue\n",
    "                est_dist = np.sqrt(max(0.0, d_qc ** 2 + dist_ic ** 2 - 2 * d_qc * dist_ic * cos_theta))\n",
    "                if est_dist > tau:\n",
    "                    continue\n",
    "                actual_dist = np.linalg.norm(x - xb[idx2])\n",
    "                best_heap.append((actual_dist, idx2))\n",
    "                if len(best_heap) > k:\n",
    "                    best_heap.sort()\n",
    "                    best_heap = best_heap[:k]\n",
    "                    tau = best_heap[-1][0]\n",
    "            inner_probed += 1\n",
    "            if probe_strategy == \"nprobe\" and inner_probed >= N_PROBE:\n",
    "                break\n",
    "    return best_heap\n",
    "\n",
    "def search_all_queries_cross_pollination(\n",
    "    xq, xq_outer_assignments, inner_kmeans, vector_metadata, xb, k, d, gt,\n",
    "    N_PROBE=1, probe_strategy=\"nprobe\", tshirt_size=\"small\", n_outer_total=10\n",
    "):\n",
    "    I = []\n",
    "    D = []\n",
    "    start_time = time.time()\n",
    "    for i, x in enumerate(xq):\n",
    "        outer_ids = xq_outer_assignments[i]\n",
    "        best_heap = search_query_cross_pollination(\n",
    "            x, outer_ids, inner_kmeans, vector_metadata, xb, k, d,\n",
    "            N_PROBE=N_PROBE, probe_strategy=probe_strategy, tshirt_size=tshirt_size, n_outer_total=n_outer_total\n",
    "        )\n",
    "        if best_heap:\n",
    "            best_heap.sort()\n",
    "            idxs = [idx for _, idx in best_heap]\n",
    "            dists = [dist for dist, _ in best_heap]\n",
    "            I.append(pad_to_k(idxs, k, -1))  # Use -1 or another invalid index as pad\n",
    "            D.append(pad_to_k(dists, k, float('inf')))\n",
    "        else:\n",
    "            dists = np.linalg.norm(xb - x.reshape(1, -1), axis=1)\n",
    "            idx = np.argsort(dists)[:k]\n",
    "            I.append(idx)\n",
    "            D.append(dists[idx])\n",
    "    D = np.array(D)\n",
    "    I = np.array(I)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    qps = len(xq) / elapsed_time\n",
    "    recall = (I == gt[:, :k]).sum() / (gt.shape[0] * k)\n",
    "    return I, D, recall, qps                                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1b4cdb05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Experiment Utilities ---\n",
    "\n",
    "def evaluate_cross_pollination(\n",
    "    xb, xq, gt, inner_kmeans, inner_to_outer, xq_outer_assignments, k, d,\n",
    "    N_PROBE=1, min_cross=1, max_cross=5, probe_strategy=\"nprobe\", tshirt_size=\"small\", n_outer_total=10\n",
    "):\n",
    "    recalls = []\n",
    "    qps_list = []\n",
    "    cross_range = range(min_cross, max_cross + 1)\n",
    "    inner_centroids = inner_kmeans.centroids\n",
    "    for N_CROSS in cross_range:\n",
    "        print(f\"Evaluating N_CROSS = {N_CROSS}\")\n",
    "        xb_inner_assignments = assign_vectors_to_clusters(xb, inner_kmeans, N_CROSS)\n",
    "        vector_metadata = cross_pollinate_metadata(\n",
    "            xb, xb_inner_assignments, inner_centroids, inner_to_outer, N_CROSS\n",
    "        )\n",
    "        build_outer_to_num_inner_clusters(vector_metadata)\n",
    "        I, D, recall, qps = search_all_queries_cross_pollination(\n",
    "            xq, xq_outer_assignments, inner_kmeans, vector_metadata, xb, k, d, gt,\n",
    "            N_PROBE=N_PROBE, probe_strategy=probe_strategy, tshirt_size=tshirt_size, n_outer_total=n_outer_total\n",
    "        )\n",
    "        recalls.append(recall)\n",
    "        qps_list.append(qps)\n",
    "        print(f\"N_CROSS={N_CROSS}: recall={recall:.4f}, qps={qps:.2f}\")\n",
    "    return cross_range, recalls, qps_list\n",
    "\n",
    "def plot_cross_pollination_results(cross_range, recalls, qps_list):\n",
    "    fig, ax1 = plt.subplots()\n",
    "    color = 'tab:blue'\n",
    "    ax1.set_xlabel('N_CROSS (number of clusters each vector is inserted into)')\n",
    "    ax1.set_ylabel('Recall', color=color)\n",
    "    ax1.plot(cross_range, recalls, marker='o', color=color)\n",
    "    ax1.tick_params(axis='y', labelcolor=color)\n",
    "    ax2 = ax1.twinx()\n",
    "    color = 'tab:red'\n",
    "    ax2.set_ylabel('QPS', color=color)\n",
    "    ax2.plot(cross_range, qps_list, marker='x', color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "    plt.title('Recall and QPS vs N_CROSS (cross-pollination)')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c69f0b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cross_pollination_experiment(\n",
    "    dataset_path,\n",
    "    n_inner_clusters=400,\n",
    "    probe_strategy=\"nprobe\",\n",
    "    N_PROBE=2,\n",
    "    min_cross=1,\n",
    "    max_cross=6,\n",
    "    tshirt_size=\"small\"\n",
    "):\n",
    "    # Load data\n",
    "    xb, xq, gt = load_fashion_mnist(dataset_path)\n",
    "    d = xb.shape[1]\n",
    "    k = 10\n",
    "\n",
    "    # Build KMeans\n",
    "    inner_kmeans = build_kmeans(xb, d, n_inner_clusters)\n",
    "    inner_centroids = inner_kmeans.centroids\n",
    "\n",
    "    outer_kmeans = build_kmeans(inner_centroids, d, 10)\n",
    "    _, inner_to_outer = outer_kmeans.index.search(inner_centroids, 1)\n",
    "    _, xq_outer_assignments = outer_kmeans.index.search(xq, 3)\n",
    "\n",
    "    # Evaluate cross-pollination\n",
    "    cross_range, recalls, qps_list = evaluate_cross_pollination(\n",
    "        xb, xq, gt, inner_kmeans, inner_to_outer, xq_outer_assignments, k, d,\n",
    "        N_PROBE=N_PROBE, min_cross=min_cross, max_cross=max_cross, probe_strategy=probe_strategy,\n",
    "        tshirt_size=tshirt_size, n_outer_total=10\n",
    "    )\n",
    "\n",
    "    # Plot results\n",
    "    plot_cross_pollination_results(cross_range, recalls, qps_list)\n",
    "    return cross_range, recalls, qps_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f9cd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify which dataset to use: \"fashion-mnist\", \"gist\", or \"sift\"\n",
    "selected_dataset = \"fashion-mnist\"\n",
    "\n",
    "DATA_URLS = {\n",
    "    \"fashion-mnist\": \"http://ann-benchmarks.com/fashion-mnist-784-euclidean.hdf5\",\n",
    "    \"gist\": \"http://ann-benchmarks.com/gist-960-euclidean.hdf5\",\n",
    "    \"sift\": \"http://ann-benchmarks.com/sift-128-euclidean.hdf5\"\n",
    "}\n",
    "CACHES = {\n",
    "    name: os.path.join(tempfile.gettempdir(), url.split('/')[-1])\n",
    "    for name, url in DATA_URLS.items()\n",
    "}\n",
    "\n",
    "# Download the selected dataset if not present\n",
    "cache_path = CACHES[selected_dataset]\n",
    "download_fashion_mnist(cache_path, DATA_URLS[selected_dataset])\n",
    "\n",
    "# Run cross-pollination experiment for the selected dataset\n",
    "print(f\"\\n=== Running experiment for {selected_dataset} ===\")\n",
    "run_cross_pollination_experiment(\n",
    "    dataset_path=cache_path,\n",
    "    n_inner_clusters=100,\n",
    "    probe_strategy=\"nprobe\",\n",
    "    N_PROBE=1,\n",
    "    min_cross=4,\n",
    "    max_cross=6,\n",
    "    tshirt_size=\"small\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
